Namespace(data='cd', batchSize=20, hidden_size=50, epoch=20, lr=0.001, l2=0.0001, user_update='rnn', item_update='rnn', user_long='orgat', item_long='orgat', user_short='att', item_short='att', feat_drop=0.3, attn_drop=0.3, layer_num=2, item_max_length=50, user_max_length=50, k_hop=2, gpu='4', last_item=False, record=True, val=False, model_record=False)
Logging to results/cd_ba_20_G_4_dim_50_ulong_orgat_ilong_orgat_US_att_IS_att_La_False_UM_50_IM_50_K_2_layer_2_l2_0.0001
train number: 421109
test number: 17052
user number: 17052
item number: 35118
start training:  2024-05-02 16:16:18.935963
Iter 400, loss 10.2825 2024-05-02 16:18:12.705276
Iter 800, loss 10.2171 2024-05-02 16:19:08.058948
Iter 1200, loss 10.1866 2024-05-02 16:20:04.448872
Iter 1600, loss 10.1579 2024-05-02 16:21:01.175834
Iter 2000, loss 10.1383 2024-05-02 16:21:58.222618
Iter 2400, loss 10.1155 2024-05-02 16:22:59.405895
Iter 2800, loss 10.0970 2024-05-02 16:23:56.838230
Iter 3200, loss 10.0762 2024-05-02 16:24:52.321087
Iter 3600, loss 10.0549 2024-05-02 16:25:48.049399
Iter 4000, loss 10.0322 2024-05-02 16:26:43.354360
Iter 4400, loss 10.0073 2024-05-02 16:27:38.768499
Iter 4800, loss 9.9844 2024-05-02 16:28:34.385536
Iter 5200, loss 9.9581 2024-05-02 16:29:30.022596
Iter 5600, loss 9.9340 2024-05-02 16:30:25.560975
Iter 6000, loss 9.9099 2024-05-02 16:31:21.405436
Iter 6400, loss 9.8871 2024-05-02 16:32:28.961250
Iter 6800, loss 9.8664 2024-05-02 16:33:35.574630
Iter 7200, loss 9.8443 2024-05-02 16:34:38.064623
Iter 7600, loss 9.8243 2024-05-02 16:35:40.850681
Iter 8000, loss 9.8057 2024-05-02 16:36:44.306210
Iter 8400, loss 9.7877 2024-05-02 16:37:47.971031
Iter 8800, loss 9.7690 2024-05-02 16:38:51.352537
Iter 9200, loss 9.7517 2024-05-02 16:39:57.290567
Iter 9600, loss 9.7354 2024-05-02 16:41:02.076515
Iter 10000, loss 9.7189 2024-05-02 16:42:00.243654
Iter 10400, loss 9.7035 2024-05-02 16:42:56.400755
Iter 10800, loss 9.6895 2024-05-02 16:43:52.017775
Iter 11200, loss 9.6756 2024-05-02 16:44:49.774483
Iter 11600, loss 9.6623 2024-05-02 16:45:45.804342
Iter 12000, loss 9.6481 2024-05-02 16:46:41.597406
Iter 12400, loss 9.6362 2024-05-02 16:47:37.969290
Iter 12800, loss 9.6246 2024-05-02 16:48:32.041542
Iter 13200, loss 9.6124 2024-05-02 16:49:33.901530
Iter 13600, loss 9.6012 2024-05-02 16:50:37.193867
Iter 14000, loss 9.5897 2024-05-02 16:51:40.708830
Iter 14400, loss 9.5782 2024-05-02 16:52:40.508784
Iter 14800, loss 9.5667 2024-05-02 16:53:34.161689
Iter 15200, loss 9.5564 2024-05-02 16:54:27.527550
Iter 15600, loss 9.5472 2024-05-02 16:55:22.022541
Iter 16000, loss 9.5370 2024-05-02 16:56:15.400180
Iter 16400, loss 9.5278 2024-05-02 16:57:08.842702
Iter 16800, loss 9.5184 2024-05-02 16:58:03.457938
Iter 17200, loss 9.5100 2024-05-02 16:59:06.835886
Iter 17600, loss 9.5015 2024-05-02 17:00:10.651897
Iter 18000, loss 9.4941 2024-05-02 17:01:14.351144
Iter 18400, loss 9.4858 2024-05-02 17:02:18.644454
Iter 18800, loss 9.4777 2024-05-02 17:03:21.785423
Iter 19200, loss 9.4701 2024-05-02 17:04:25.495361
Iter 19600, loss 9.4627 2024-05-02 17:05:29.009993
Iter 20000, loss 9.4553 2024-05-02 17:06:32.284141
Iter 20400, loss 9.4482 2024-05-02 17:07:34.885381
Iter 20800, loss 9.4413 2024-05-02 17:08:37.642038
Epoch 0, loss 9.4371 =============================================
start predicting:  2024-05-02 17:10:17.625450
Iter 200, test_loss 9.3175 2024-05-02 17:11:43.219595
Iter 400, test_loss 9.4406 2024-05-02 17:11:54.693638
Iter 600, test_loss 9.3691 2024-05-02 17:12:09.382192
Iter 800, test_loss 9.2977 2024-05-02 17:12:24.400449
train_loss:9.4371	test_loss:9.2875	Recall@5:0.4520	Recall@10:0.5784	Recall@20:0.7042	NDGG@5:0.3351	NDGG10@10:0.3760	NDGG@20:0.4077	Epoch:0,0,0,0,0,0
start training:  2024-05-02 17:13:08.321920
Iter 400, loss 8.9091 2024-05-02 17:14:28.003066
Iter 800, loss 8.9043 2024-05-02 17:15:26.719971
Iter 1200, loss 8.9139 2024-05-02 17:16:34.069789
Iter 1600, loss 8.9262 2024-05-02 17:17:44.900410
Iter 2000, loss 8.9288 2024-05-02 17:18:54.555868
Iter 2400, loss 8.9311 2024-05-02 17:20:05.282100
Iter 2800, loss 8.9393 2024-05-02 17:21:14.937932
Iter 3200, loss 8.9434 2024-05-02 17:22:24.948936
Iter 3600, loss 8.9476 2024-05-02 17:23:35.536948
Iter 4000, loss 8.9519 2024-05-02 17:24:46.557066
Iter 4400, loss 8.9555 2024-05-02 17:25:57.637607
Iter 4800, loss 8.9589 2024-05-02 17:27:07.631577
Iter 5200, loss 8.9598 2024-05-02 17:28:18.748089
Iter 5600, loss 8.9640 2024-05-02 17:29:28.822112
Iter 6000, loss 8.9694 2024-05-02 17:30:38.719397
Iter 6400, loss 8.9722 2024-05-02 17:31:49.495014
Iter 6800, loss 8.9736 2024-05-02 17:33:00.129665
Iter 7200, loss 8.9752 2024-05-02 17:34:11.845261
Iter 7600, loss 8.9764 2024-05-02 17:35:22.644197
Iter 8000, loss 8.9775 2024-05-02 17:36:33.314849
Iter 8400, loss 8.9777 2024-05-02 17:37:44.065199
Iter 8800, loss 8.9772 2024-05-02 17:38:54.746336
Iter 9200, loss 8.9775 2024-05-02 17:40:05.931610
Iter 9600, loss 8.9781 2024-05-02 17:41:17.201927
Iter 10000, loss 8.9785 2024-05-02 17:42:27.817551
Iter 10400, loss 8.9791 2024-05-02 17:43:38.755310
Iter 10800, loss 8.9789 2024-05-02 17:44:49.440175
Iter 11200, loss 8.9782 2024-05-02 17:45:59.675254
Iter 11600, loss 8.9778 2024-05-02 17:47:10.140963
Iter 12000, loss 8.9772 2024-05-02 17:48:20.695100
Iter 12400, loss 8.9772 2024-05-02 17:49:31.337935
Iter 12800, loss 8.9761 2024-05-02 17:50:42.518526
Iter 13200, loss 8.9756 2024-05-02 17:51:53.894470
Iter 13600, loss 8.9746 2024-05-02 17:53:05.089808
Iter 14000, loss 8.9742 2024-05-02 17:54:12.677105
Iter 14400, loss 8.9743 2024-05-02 17:55:11.462759
Iter 14800, loss 8.9734 2024-05-02 17:56:10.257349
Iter 15200, loss 8.9722 2024-05-02 17:57:20.981034
Iter 15600, loss 8.9713 2024-05-02 17:58:32.174195
Iter 16000, loss 8.9700 2024-05-02 17:59:42.794204
Iter 16400, loss 8.9688 2024-05-02 18:00:54.198115
Iter 16800, loss 8.9670 2024-05-02 18:02:05.370031
Iter 17200, loss 8.9661 2024-05-02 18:03:15.877988
Iter 17600, loss 8.9650 2024-05-02 18:04:26.454347
Iter 18000, loss 8.9643 2024-05-02 18:05:30.407759
Iter 18400, loss 8.9622 2024-05-02 18:06:29.575034
Iter 18800, loss 8.9614 2024-05-02 18:07:29.064759
Iter 19200, loss 8.9600 2024-05-02 18:08:42.390214
Iter 19600, loss 8.9587 2024-05-02 18:09:54.505391
Iter 20000, loss 8.9581 2024-05-02 18:11:09.448875
Iter 20400, loss 8.9569 2024-05-02 18:12:21.755645
Iter 20800, loss 8.9559 2024-05-02 18:13:32.388036
Epoch 1, loss 8.9552 =============================================
start predicting:  2024-05-02 18:15:17.400906
Iter 200, test_loss 9.1187 2024-05-02 18:16:49.390734
Iter 400, test_loss 9.2523 2024-05-02 18:17:03.566350
Iter 600, test_loss 9.1784 2024-05-02 18:17:19.586502
Iter 800, test_loss 9.0922 2024-05-02 18:17:35.983674
train_loss:8.9552	test_loss:9.0790	Recall@5:0.5025	Recall@10:0.6236	Recall@20:0.7392	NDGG@5:0.3821	NDGG10@10:0.4213	NDGG@20:0.4506	Epoch:1,1,1,1,1,1
start training:  2024-05-02 18:18:20.327352
Iter 400, loss 8.6585 2024-05-02 18:19:47.566501
Iter 800, loss 8.6532 2024-05-02 18:20:51.370774
Iter 1200, loss 8.6766 2024-05-02 18:21:53.570120
Iter 1600, loss 8.6973 2024-05-02 18:22:55.661441
Iter 2000, loss 8.7034 2024-05-02 18:24:00.115859
Iter 2400, loss 8.7134 2024-05-02 18:25:08.409768
Iter 2800, loss 8.7243 2024-05-02 18:26:16.976339
Iter 3200, loss 8.7370 2024-05-02 18:27:25.613372
Iter 3600, loss 8.7436 2024-05-02 18:28:34.304977
Iter 4000, loss 8.7517 2024-05-02 18:29:43.597125
Iter 4400, loss 8.7581 2024-05-02 18:30:52.389967
Iter 4800, loss 8.7666 2024-05-02 18:32:01.332174
Iter 5200, loss 8.7708 2024-05-02 18:33:10.497576
Iter 5600, loss 8.7752 2024-05-02 18:34:19.413681
Iter 6000, loss 8.7762 2024-05-02 18:35:27.909020
Iter 6400, loss 8.7814 2024-05-02 18:36:37.393184
Iter 6800, loss 8.7849 2024-05-02 18:37:46.317906
Iter 7200, loss 8.7896 2024-05-02 18:38:51.376341
Iter 7600, loss 8.7926 2024-05-02 18:39:53.075919
Iter 8000, loss 8.7949 2024-05-02 18:40:52.588533
Iter 8400, loss 8.7969 2024-05-02 18:41:52.337919
Iter 8800, loss 8.7994 2024-05-02 18:42:51.705360
Iter 9200, loss 8.8007 2024-05-02 18:43:50.736474
Iter 9600, loss 8.8039 2024-05-02 18:44:50.029040
Iter 10000, loss 8.8053 2024-05-02 18:45:51.084646
Iter 10400, loss 8.8081 2024-05-02 18:46:51.885274
Iter 10800, loss 8.8101 2024-05-02 18:47:52.941383
Iter 11200, loss 8.8105 2024-05-02 18:48:54.152269
Iter 11600, loss 8.8126 2024-05-02 18:49:54.947207
Iter 12000, loss 8.8136 2024-05-02 18:50:55.644956
Iter 12400, loss 8.8165 2024-05-02 18:51:57.001994
Iter 12800, loss 8.8182 2024-05-02 18:52:58.105449
Iter 13200, loss 8.8196 2024-05-02 18:54:01.438505
Iter 13600, loss 8.8207 2024-05-02 18:55:14.528662
Iter 14000, loss 8.8208 2024-05-02 18:56:26.666053
Iter 14400, loss 8.8210 2024-05-02 18:57:27.835890
Iter 14800, loss 8.8225 2024-05-02 18:58:37.220640
Iter 15200, loss 8.8235 2024-05-02 18:59:49.123701
Iter 15600, loss 8.8243 2024-05-02 19:01:01.638726
Iter 16000, loss 8.8250 2024-05-02 19:02:13.634133
Iter 16400, loss 8.8259 2024-05-02 19:03:25.656899
Iter 16800, loss 8.8266 2024-05-02 19:04:37.365580
Iter 17200, loss 8.8267 2024-05-02 19:05:49.193409
Iter 17600, loss 8.8273 2024-05-02 19:07:01.057386
Iter 18000, loss 8.8276 2024-05-02 19:08:13.116652
Iter 18400, loss 8.8278 2024-05-02 19:09:22.046403
Iter 18800, loss 8.8284 2024-05-02 19:10:23.308877
Iter 19200, loss 8.8279 2024-05-02 19:11:24.137588
Iter 19600, loss 8.8283 2024-05-02 19:12:25.689514
Iter 20000, loss 8.8288 2024-05-02 19:13:27.156641
Iter 20400, loss 8.8295 2024-05-02 19:14:28.441025
Iter 20800, loss 8.8293 2024-05-02 19:15:29.952149
Epoch 2, loss 8.8285 =============================================
start predicting:  2024-05-02 19:17:10.838752
Iter 200, test_loss 9.1073 2024-05-02 19:18:31.255934
Iter 400, test_loss 9.2159 2024-05-02 19:18:42.977656
Iter 600, test_loss 9.1389 2024-05-02 19:18:57.522853
Iter 800, test_loss 9.0639 2024-05-02 19:19:12.170372
train_loss:8.8285	test_loss:9.0513	Recall@5:0.5025	Recall@10:0.6237	Recall@20:0.7462	NDGG@5:0.3836	NDGG10@10:0.4233	NDGG@20:0.4542	Epoch:1,2,2,2,2,2
start training:  2024-05-02 19:19:56.067671
Iter 400, loss 8.5763 2024-05-02 19:21:17.307853
Iter 800, loss 8.5656 2024-05-02 19:22:16.631098
Iter 1200, loss 8.5773 2024-05-02 19:23:15.783205
Iter 1600, loss 8.6002 2024-05-02 19:24:15.527878
Iter 2000, loss 8.6140 2024-05-02 19:25:15.015270
Iter 2400, loss 8.6334 2024-05-02 19:26:15.299136
Iter 2800, loss 8.6451 2024-05-02 19:27:15.785058
Iter 3200, loss 8.6546 2024-05-02 19:28:23.726881
Iter 3600, loss 8.6635 2024-05-02 19:29:37.039293
Iter 4000, loss 8.6676 2024-05-02 19:30:49.944487
Iter 4400, loss 8.6779 2024-05-02 19:32:02.781541
Iter 4800, loss 8.6843 2024-05-02 19:33:15.847070
Iter 5200, loss 8.6883 2024-05-02 19:34:28.794102
Iter 5600, loss 8.6928 2024-05-02 19:35:41.425425
Iter 6000, loss 8.6988 2024-05-02 19:36:54.408358
Iter 6400, loss 8.7038 2024-05-02 19:38:06.915170
Iter 6800, loss 8.7081 2024-05-02 19:39:19.732819
Iter 7200, loss 8.7108 2024-05-02 19:40:33.803895
Iter 7600, loss 8.7137 2024-05-02 19:41:47.715500
Iter 8000, loss 8.7172 2024-05-02 19:43:01.668323
Iter 8400, loss 8.7225 2024-05-02 19:44:15.811692
Iter 8800, loss 8.7258 2024-05-02 19:45:30.069499
Iter 9200, loss 8.7284 2024-05-02 19:46:45.036467
Iter 9600, loss 8.7316 2024-05-02 19:47:58.023200
Iter 10000, loss 8.7349 2024-05-02 19:49:09.851470
Iter 10400, loss 8.7385 2024-05-02 19:50:22.959103
Iter 10800, loss 8.7409 2024-05-02 19:51:35.208873
Iter 11200, loss 8.7427 2024-05-02 19:52:48.057053
Iter 11600, loss 8.7449 2024-05-02 19:53:59.460106
Iter 12000, loss 8.7477 2024-05-02 19:55:14.439347
Iter 12400, loss 8.7499 2024-05-02 19:56:28.320627
Iter 12800, loss 8.7528 2024-05-02 19:57:33.394864
Iter 13200, loss 8.7537 2024-05-02 19:58:51.920626
Iter 13600, loss 8.7557 2024-05-02 19:59:57.077217
Iter 14000, loss 8.7575 2024-05-02 20:00:59.411326
Iter 14400, loss 8.7595 2024-05-02 20:02:02.739928
Iter 14800, loss 8.7603 2024-05-02 20:03:09.150689
Iter 15200, loss 8.7613 2024-05-02 20:04:10.560475
Iter 15600, loss 8.7627 2024-05-02 20:05:11.194502
Iter 16000, loss 8.7641 2024-05-02 20:06:11.900619
Iter 16400, loss 8.7656 2024-05-02 20:07:13.933819
Iter 16800, loss 8.7659 2024-05-02 20:08:14.732728
Iter 17200, loss 8.7672 2024-05-02 20:09:16.109031
Iter 17600, loss 8.7678 2024-05-02 20:10:17.215481
Iter 18000, loss 8.7680 2024-05-02 20:11:18.145388
Iter 18400, loss 8.7693 2024-05-02 20:12:18.950332
Iter 18800, loss 8.7704 2024-05-02 20:13:18.690836
Iter 19200, loss 8.7717 2024-05-02 20:14:18.863418
Iter 19600, loss 8.7726 2024-05-02 20:15:21.227260
Iter 20000, loss 8.7729 2024-05-02 20:16:21.409109
Iter 20400, loss 8.7734 2024-05-02 20:17:22.224847
Iter 20800, loss 8.7740 2024-05-02 20:18:23.604497
Epoch 3, loss 8.7743 =============================================
start predicting:  2024-05-02 20:20:02.750038
Iter 200, test_loss 9.0709 2024-05-02 20:21:27.089282
Iter 400, test_loss 9.2014 2024-05-02 20:21:39.222017
Iter 600, test_loss 9.1277 2024-05-02 20:21:54.273137
Iter 800, test_loss 9.0496 2024-05-02 20:22:09.389309
train_loss:8.7743	test_loss:9.0431	Recall@5:0.5113	Recall@10:0.6321	Recall@20:0.7495	NDGG@5:0.3897	NDGG10@10:0.4288	NDGG@20:0.4585	Epoch:3,3,3,3,3,3
start training:  2024-05-02 20:22:53.258357
Iter 400, loss 8.4664 2024-05-02 20:24:13.842476
Iter 800, loss 8.5046 2024-05-02 20:25:12.592565
Iter 1200, loss 8.5347 2024-05-02 20:26:11.082627
Iter 1600, loss 8.5406 2024-05-02 20:27:09.389954
Iter 2000, loss 8.5591 2024-05-02 20:28:08.033224
Iter 2400, loss 8.5780 2024-05-02 20:29:06.440788
Iter 2800, loss 8.5879 2024-05-02 20:30:06.417909
Iter 3200, loss 8.5981 2024-05-02 20:31:07.310251
Iter 3600, loss 8.6097 2024-05-02 20:32:08.050383
Iter 4000, loss 8.6218 2024-05-02 20:33:08.795116
Iter 4400, loss 8.6283 2024-05-02 20:34:11.355035
Iter 4800, loss 8.6366 2024-05-02 20:35:14.702923
Iter 5200, loss 8.6407 2024-05-02 20:36:18.566189
Iter 5600, loss 8.6466 2024-05-02 20:37:21.976533
Iter 6000, loss 8.6543 2024-05-02 20:38:23.972712
Iter 6400, loss 8.6612 2024-05-02 20:39:26.512818
Iter 6800, loss 8.6651 2024-05-02 20:40:30.730781
Iter 7200, loss 8.6709 2024-05-02 20:41:35.230614
Iter 7600, loss 8.6778 2024-05-02 20:42:38.004588
Iter 8000, loss 8.6810 2024-05-02 20:43:40.852063
Iter 8400, loss 8.6837 2024-05-02 20:44:42.307284
Iter 8800, loss 8.6884 2024-05-02 20:45:44.041724
Iter 9200, loss 8.6929 2024-05-02 20:46:48.756692
Iter 9600, loss 8.6956 2024-05-02 20:48:01.857315
Iter 10000, loss 8.6987 2024-05-02 20:49:04.796636
Iter 10400, loss 8.7003 2024-05-02 20:50:08.879867
Iter 10800, loss 8.7029 2024-05-02 20:51:10.947207
Iter 11200, loss 8.7050 2024-05-02 20:52:15.622101
Iter 11600, loss 8.7071 2024-05-02 20:53:18.773009
Iter 12000, loss 8.7080 2024-05-02 20:54:21.528965
Iter 12400, loss 8.7094 2024-05-02 20:55:22.424892
Iter 12800, loss 8.7128 2024-05-02 20:56:23.697353
Iter 13200, loss 8.7154 2024-05-02 20:57:25.479641
Iter 13600, loss 8.7171 2024-05-02 20:58:27.011450
Iter 14000, loss 8.7197 2024-05-02 20:59:33.693493
Iter 14400, loss 8.7221 2024-05-02 21:00:35.249463
Iter 14800, loss 8.7236 2024-05-02 21:01:38.534729
Iter 15200, loss 8.7236 2024-05-02 21:02:51.838250
Iter 15600, loss 8.7236 2024-05-02 21:04:04.009501
Iter 16000, loss 8.7245 2024-05-02 21:05:16.104294
Iter 16400, loss 8.7270 2024-05-02 21:06:27.543059
Iter 16800, loss 8.7282 2024-05-02 21:07:37.865480
Iter 17200, loss 8.7294 2024-05-02 21:08:48.611021
Iter 17600, loss 8.7299 2024-05-02 21:10:00.714143
Iter 18000, loss 8.7319 2024-05-02 21:11:12.427962
Iter 18400, loss 8.7335 2024-05-02 21:12:24.697696
Iter 18800, loss 8.7341 2024-05-02 21:13:36.756707
Iter 19200, loss 8.7355 2024-05-02 21:19:50.400704
Iter 19600, loss 8.7366 2024-05-02 21:22:36.899395
Iter 20000, loss 8.7368 2024-05-02 21:23:40.447988
Iter 20400, loss 8.7376 2024-05-02 21:24:42.097722
Iter 20800, loss 8.7390 2024-05-02 21:25:42.866510
Epoch 4, loss 8.7395 =============================================
start predicting:  2024-05-02 21:27:22.484718
Iter 200, test_loss 9.0765 2024-05-02 21:28:50.850978
Iter 400, test_loss 9.1903 2024-05-02 21:29:03.319491
Iter 600, test_loss 9.1152 2024-05-02 21:29:18.872144
Iter 800, test_loss 9.0384 2024-05-02 21:29:33.784236
train_loss:8.7395	test_loss:9.0289	Recall@5:0.5169	Recall@10:0.6341	Recall@20:0.7533	NDGG@5:0.3909	NDGG10@10:0.4289	NDGG@20:0.4591	Epoch:4,4,4,4,4,4
start training:  2024-05-02 21:30:17.605129
Iter 400, loss 8.4559 2024-05-02 21:31:44.960752
Iter 800, loss 8.4600 2024-05-02 21:32:44.770470
Iter 1200, loss 8.4824 2024-05-02 21:33:48.316138
Iter 1600, loss 8.5007 2024-05-02 21:34:49.322684
Iter 2000, loss 8.5142 2024-05-02 21:35:50.692902
Iter 2400, loss 8.5316 2024-05-02 21:36:53.649340
Iter 2800, loss 8.5443 2024-05-02 21:37:58.740753
Iter 3200, loss 8.5559 2024-05-02 21:39:01.349054
Iter 3600, loss 8.5660 2024-05-02 21:40:05.929348
Iter 4000, loss 8.5726 2024-05-02 21:41:11.520972
Iter 4400, loss 8.5805 2024-05-02 21:42:13.104199
Iter 4800, loss 8.5927 2024-05-02 21:43:16.818198
Iter 5200, loss 8.5995 2024-05-02 21:44:20.551118
Iter 5600, loss 8.6070 2024-05-02 21:45:21.600285
Iter 6000, loss 8.6134 2024-05-02 21:46:23.328018
Iter 6400, loss 8.6186 2024-05-02 21:47:22.784265
Iter 6800, loss 8.6243 2024-05-02 21:48:22.740763
Iter 7200, loss 8.6304 2024-05-02 21:49:26.103421
Iter 7600, loss 8.6374 2024-05-02 21:50:29.182870
Iter 8000, loss 8.6426 2024-05-02 21:51:30.637277
Iter 8400, loss 8.6477 2024-05-02 21:52:33.688065
Iter 8800, loss 8.6530 2024-05-02 21:53:39.035384
Iter 9200, loss 8.6577 2024-05-02 21:54:41.170041
Iter 9600, loss 8.6610 2024-05-02 21:55:43.326152
Iter 10000, loss 8.6631 2024-05-02 21:56:43.607773
Iter 10400, loss 8.6675 2024-05-02 21:57:43.541401
Iter 10800, loss 8.6719 2024-05-02 21:58:43.131687
Iter 11200, loss 8.6737 2024-05-02 21:59:45.576725
Iter 11600, loss 8.6768 2024-05-02 22:00:49.160174
Iter 12000, loss 8.6786 2024-05-02 22:01:52.273562
Iter 12400, loss 8.6808 2024-05-02 22:03:01.499182
Iter 12800, loss 8.6834 2024-05-02 22:04:06.207422
Iter 13200, loss 8.6859 2024-05-02 22:05:09.235193
Iter 13600, loss 8.6875 2024-05-02 22:06:11.810932
Iter 14000, loss 8.6892 2024-05-02 22:07:13.273668
Iter 14400, loss 8.6911 2024-05-02 22:08:15.039098
Iter 14800, loss 8.6917 2024-05-02 22:09:15.706594
Iter 15200, loss 8.6940 2024-05-02 22:10:15.674551
Iter 15600, loss 8.6960 2024-05-02 22:11:16.984875
Iter 16000, loss 8.6967 2024-05-02 22:12:18.630262
Iter 16400, loss 8.6980 2024-05-02 22:13:20.979003
Iter 16800, loss 8.6992 2024-05-02 22:14:23.022815
Iter 17200, loss 8.7004 2024-05-02 22:15:25.323101
Iter 17600, loss 8.7018 2024-05-02 22:16:28.063629
Iter 18000, loss 8.7034 2024-05-02 22:17:30.732400
Iter 18400, loss 8.7041 2024-05-02 22:18:31.874248
Iter 18800, loss 8.7049 2024-05-02 22:19:33.612626
Iter 19200, loss 8.7054 2024-05-02 22:20:35.588889
Iter 19600, loss 8.7071 2024-05-02 22:21:35.375621
Iter 20000, loss 8.7085 2024-05-02 22:22:35.617785
Iter 20400, loss 8.7093 2024-05-02 22:23:35.640174
Iter 20800, loss 8.7109 2024-05-02 22:24:36.669587
Epoch 5, loss 8.7117 =============================================
start predicting:  2024-05-02 22:26:17.418329
Iter 200, test_loss 9.0407 2024-05-02 22:27:41.228768
Iter 400, test_loss 9.1622 2024-05-02 22:27:54.013599
Iter 600, test_loss 9.0885 2024-05-02 22:28:09.729697
Iter 800, test_loss 9.0059 2024-05-02 22:28:24.724767
train_loss:8.7117	test_loss:8.9955	Recall@5:0.5234	Recall@10:0.6382	Recall@20:0.7559	NDGG@5:0.3989	NDGG10@10:0.4361	NDGG@20:0.4659	Epoch:5,5,5,5,5,5
start training:  2024-05-02 22:29:08.729494
Iter 400, loss 8.3797 2024-05-02 22:30:33.423175
Iter 800, loss 8.4354 2024-05-02 22:31:35.011955
Iter 1200, loss 8.4465 2024-05-02 22:32:38.237666
Iter 1600, loss 8.4720 2024-05-02 22:33:38.325573
Iter 2000, loss 8.4863 2024-05-02 22:34:45.303286
Iter 2400, loss 8.5023 2024-05-02 22:36:00.973209
Iter 2800, loss 8.5175 2024-05-02 22:37:00.442546
Iter 3200, loss 8.5316 2024-05-02 22:37:58.203051
Iter 3600, loss 8.5361 2024-05-02 22:38:56.405688
Iter 4000, loss 8.5454 2024-05-02 22:39:55.219182
Iter 4400, loss 8.5570 2024-05-02 22:40:54.147718
Iter 4800, loss 8.5691 2024-05-02 22:41:55.299305
Iter 5200, loss 8.5779 2024-05-02 22:43:02.847186
Iter 5600, loss 8.5824 2024-05-02 22:44:18.520484
Iter 6000, loss 8.5905 2024-05-02 22:45:33.166923
Iter 6400, loss 8.5943 2024-05-02 22:46:49.303978
Iter 6800, loss 8.5999 2024-05-02 22:48:05.711653
Iter 7200, loss 8.6064 2024-05-02 22:49:22.501386
Iter 7600, loss 8.6104 2024-05-02 22:50:39.782528
Iter 8000, loss 8.6162 2024-05-02 22:51:57.486261
Iter 8400, loss 8.6215 2024-05-02 22:53:13.372271
Iter 8800, loss 8.6258 2024-05-02 22:54:29.498243
Iter 9200, loss 8.6291 2024-05-02 22:55:30.816524
Iter 9600, loss 8.6328 2024-05-02 22:56:31.211012
Iter 10000, loss 8.6353 2024-05-02 22:57:31.783048
Iter 10400, loss 8.6395 2024-05-02 22:58:33.910475
Iter 10800, loss 8.6429 2024-05-02 22:59:35.278858
Iter 11200, loss 8.6469 2024-05-02 23:00:36.769709
Iter 11600, loss 8.6485 2024-05-02 23:01:40.774783
Iter 12000, loss 8.6495 2024-05-02 23:02:44.830996
Iter 12400, loss 8.6525 2024-05-02 23:03:42.716321
Iter 12800, loss 8.6551 2024-05-02 23:04:41.296270
Iter 13200, loss 8.6571 2024-05-02 23:05:49.023932
Iter 13600, loss 8.6595 2024-05-02 23:07:08.576820
Iter 14000, loss 8.6606 2024-05-02 23:08:25.525993
Iter 14400, loss 8.6631 2024-05-02 23:09:38.166370
Iter 14800, loss 8.6640 2024-05-02 23:10:38.486906
Iter 15200, loss 8.6661 2024-05-02 23:11:54.494429
Iter 15600, loss 8.6687 2024-05-02 23:13:11.449059
Iter 16000, loss 8.6695 2024-05-02 23:14:27.263668
Iter 16400, loss 8.6721 2024-05-02 23:15:43.076827
Iter 16800, loss 8.6738 2024-05-02 23:16:59.244440
Iter 17200, loss 8.6753 2024-05-02 23:17:58.312145
Iter 17600, loss 8.6766 2024-05-02 23:18:57.497791
Iter 18000, loss 8.6793 2024-05-02 23:19:56.793336
Iter 18400, loss 8.6808 2024-05-02 23:21:03.819014
Iter 18800, loss 8.6822 2024-05-02 23:22:20.084306
Iter 19200, loss 8.6838 2024-05-02 23:23:34.823641
Iter 19600, loss 8.6850 2024-05-02 23:24:50.193038
Iter 20000, loss 8.6862 2024-05-02 23:26:05.008936
Iter 20400, loss 8.6871 2024-05-02 23:27:22.551092
Iter 20800, loss 8.6880 2024-05-02 23:28:39.628871
Epoch 6, loss 8.6886 =============================================
start predicting:  2024-05-02 23:30:27.538170
Iter 200, test_loss 9.0127 2024-05-02 23:31:57.178284
Iter 400, test_loss 9.1466 2024-05-02 23:32:09.213721
Iter 600, test_loss 9.0555 2024-05-02 23:32:24.597546
Iter 800, test_loss 8.9744 2024-05-02 23:32:40.239078
train_loss:8.6886	test_loss:8.9631	Recall@5:0.5243	Recall@10:0.6433	Recall@20:0.7609	NDGG@5:0.4019	NDGG10@10:0.4405	NDGG@20:0.4702	Epoch:6,6,6,6,6,6
start training:  2024-05-02 23:33:24.455388
Iter 400, loss 8.4019 2024-05-02 23:34:48.906031
Iter 800, loss 8.4139 2024-05-02 23:35:47.840956
Iter 1200, loss 8.4324 2024-05-02 23:36:47.157289
Iter 1600, loss 8.4504 2024-05-02 23:37:48.083944
Iter 2000, loss 8.4613 2024-05-02 23:38:50.815444
Iter 2400, loss 8.4846 2024-05-02 23:39:53.922594
Iter 2800, loss 8.4997 2024-05-02 23:40:54.368511
Iter 3200, loss 8.5154 2024-05-02 23:41:57.297042
Iter 3600, loss 8.5220 2024-05-02 23:43:00.511892
Iter 4000, loss 8.5321 2024-05-02 23:44:01.769851
Iter 4400, loss 8.5382 2024-05-02 23:45:02.759290
Iter 4800, loss 8.5453 2024-05-02 23:46:16.915569
Iter 5200, loss 8.5524 2024-05-02 23:47:34.596690
Iter 5600, loss 8.5599 2024-05-02 23:48:53.016287
Iter 6000, loss 8.5643 2024-05-02 23:50:09.091994
Iter 6400, loss 8.5718 2024-05-02 23:51:23.933722
Iter 6800, loss 8.5781 2024-05-02 23:52:39.284122
Iter 7200, loss 8.5834 2024-05-02 23:53:54.765411
Iter 7600, loss 8.5910 2024-05-02 23:55:09.996836
Iter 8000, loss 8.5940 2024-05-02 23:56:25.559873
Iter 8400, loss 8.5978 2024-05-02 23:57:39.952944
Iter 8800, loss 8.6024 2024-05-02 23:58:55.778560
Iter 9200, loss 8.6084 2024-05-03 00:00:11.456209
Iter 9600, loss 8.6111 2024-05-03 00:01:26.966563
Iter 10000, loss 8.6134 2024-05-03 00:02:42.592546
Iter 10400, loss 8.6166 2024-05-03 00:03:58.745451
Iter 10800, loss 8.6195 2024-05-03 00:05:14.229085
Iter 11200, loss 8.6237 2024-05-03 00:06:30.269253
Iter 11600, loss 8.6270 2024-05-03 00:07:46.561121
Iter 12000, loss 8.6291 2024-05-03 00:08:53.783791
Iter 12400, loss 8.6318 2024-05-03 00:09:53.212937
Iter 12800, loss 8.6341 2024-05-03 00:10:55.102124
Iter 13200, loss 8.6376 2024-05-03 00:11:58.323725
Iter 13600, loss 8.6400 2024-05-03 00:12:57.911685
Iter 14000, loss 8.6424 2024-05-03 00:14:00.748921
Iter 14400, loss 8.6444 2024-05-03 00:15:04.446328
Iter 14800, loss 8.6466 2024-05-03 00:16:07.119372
Iter 15200, loss 8.6483 2024-05-03 00:17:13.339647
Iter 15600, loss 8.6499 2024-05-03 00:18:15.023852
Iter 16000, loss 8.6517 2024-05-03 00:19:19.096000
Iter 16400, loss 8.6536 2024-05-03 00:20:22.967932
Iter 16800, loss 8.6550 2024-05-03 00:21:25.416552
Iter 17200, loss 8.6562 2024-05-03 00:22:29.099345
Iter 17600, loss 8.6572 2024-05-03 00:23:31.766673
Iter 18000, loss 8.6592 2024-05-03 00:24:37.683359
Iter 18400, loss 8.6610 2024-05-03 00:25:49.349200
Iter 18800, loss 8.6624 2024-05-03 00:26:59.124684
Iter 19200, loss 8.6643 2024-05-03 00:28:08.035053
Iter 19600, loss 8.6655 2024-05-03 00:29:16.565405
Iter 20000, loss 8.6670 2024-05-03 00:30:25.892194
Iter 20400, loss 8.6675 2024-05-03 00:31:34.193035
Iter 20800, loss 8.6695 2024-05-03 00:32:42.123742
Epoch 7, loss 8.6705 =============================================
start predicting:  2024-05-03 00:34:25.498429
Iter 200, test_loss 9.0095 2024-05-03 00:35:55.724276
Iter 400, test_loss 9.1231 2024-05-03 00:36:08.873887
Iter 600, test_loss 9.0420 2024-05-03 00:36:24.814438
Iter 800, test_loss 8.9675 2024-05-03 00:36:40.664257
train_loss:8.6705	test_loss:8.9536	Recall@5:0.5285	Recall@10:0.6480	Recall@20:0.7617	NDGG@5:0.4024	NDGG10@10:0.4410	NDGG@20:0.4702	Epoch:7,7,7,7,7,6
start training:  2024-05-03 00:37:24.890883
Iter 400, loss 8.3571 2024-05-03 00:38:55.672374
Iter 800, loss 8.3781 2024-05-03 00:40:10.645678
Iter 1200, loss 8.4115 2024-05-03 00:41:32.626004
Iter 1600, loss 8.4271 2024-05-03 00:42:52.205646
Iter 2000, loss 8.4385 2024-05-03 00:44:08.910535
Iter 2400, loss 8.4588 2024-05-03 00:45:26.204485
Iter 2800, loss 8.4751 2024-05-03 00:46:41.069258
Iter 3200, loss 8.4855 2024-05-03 00:47:55.544214
Iter 3600, loss 8.4969 2024-05-03 00:49:10.169268
Iter 4000, loss 8.5111 2024-05-03 00:50:25.180952
Iter 4400, loss 8.5221 2024-05-03 00:51:41.700037
Iter 4800, loss 8.5316 2024-05-03 00:52:55.916964
Iter 5200, loss 8.5404 2024-05-03 00:54:11.743109
Iter 5600, loss 8.5453 2024-05-03 00:55:27.990777
Iter 6000, loss 8.5505 2024-05-03 00:56:43.989447
Iter 6400, loss 8.5570 2024-05-03 00:57:59.734632
Iter 6800, loss 8.5635 2024-05-03 00:59:15.818799
Iter 7200, loss 8.5700 2024-05-03 01:00:31.970103
Iter 7600, loss 8.5733 2024-05-03 01:01:48.425113
Iter 8000, loss 8.5781 2024-05-03 01:03:05.608113
Iter 8400, loss 8.5828 2024-05-03 01:04:21.554628
Iter 8800, loss 8.5863 2024-05-03 01:05:37.976110
Iter 9200, loss 8.5914 2024-05-03 01:06:54.938931
Iter 9600, loss 8.5959 2024-05-03 01:08:11.553561
Iter 10000, loss 8.6002 2024-05-03 01:09:28.558578
Iter 10400, loss 8.6041 2024-05-03 01:10:46.254925
Iter 10800, loss 8.6085 2024-05-03 01:12:02.643571
Iter 11200, loss 8.6111 2024-05-03 01:13:19.899642
Iter 11600, loss 8.6134 2024-05-03 01:14:35.630696
Iter 12000, loss 8.6172 2024-05-03 01:15:53.169608
Iter 12400, loss 8.6204 2024-05-03 01:17:09.445906
Iter 12800, loss 8.6227 2024-05-03 01:18:26.629625
Iter 13200, loss 8.6247 2024-05-03 01:19:43.206413
Iter 13600, loss 8.6271 2024-05-03 01:20:59.965307
Iter 14000, loss 8.6283 2024-05-03 01:22:17.101778
Iter 14400, loss 8.6317 2024-05-03 01:23:33.570230
Iter 14800, loss 8.6336 2024-05-03 01:24:50.549308
Iter 15200, loss 8.6348 2024-05-03 01:26:06.141279
Iter 15600, loss 8.6366 2024-05-03 01:27:22.334386
Iter 16000, loss 8.6380 2024-05-03 01:28:37.807442
Iter 16400, loss 8.6409 2024-05-03 01:29:53.552177
Iter 16800, loss 8.6429 2024-05-03 01:31:09.286505
Iter 17200, loss 8.6445 2024-05-03 01:32:25.744783
Iter 17600, loss 8.6461 2024-05-03 01:33:41.290435
Iter 18000, loss 8.6472 2024-05-03 01:34:58.149436
Iter 18400, loss 8.6487 2024-05-03 01:36:14.521394
Iter 18800, loss 8.6504 2024-05-03 01:37:31.032406
Iter 19200, loss 8.6518 2024-05-03 01:38:48.296966
Iter 19600, loss 8.6536 2024-05-03 01:39:52.896397
Iter 20000, loss 8.6552 2024-05-03 01:41:06.987241
Iter 20400, loss 8.6559 2024-05-03 01:42:23.622118
Iter 20800, loss 8.6566 2024-05-03 01:43:41.027059
Epoch 8, loss 8.6578 =============================================
start predicting:  2024-05-03 01:45:30.523087
Iter 200, test_loss 9.0341 2024-05-03 01:46:56.525489
Iter 400, test_loss 9.1404 2024-05-03 01:47:09.063465
Iter 600, test_loss 9.0644 2024-05-03 01:47:24.289799
Iter 800, test_loss 8.9819 2024-05-03 01:47:39.058855
train_loss:8.6578	test_loss:8.9697	Recall@5:0.5285	Recall@10:0.6480	Recall@20:0.7617	NDGG@5:0.4040	NDGG10@10:0.4410	NDGG@20:0.4709	Epoch:7,7,7,8,7,8
start training:  2024-05-03 01:48:22.944483
Iter 400, loss 8.3635 2024-05-03 01:49:53.649420
Iter 800, loss 8.3769 2024-05-03 01:51:01.878484
Iter 1200, loss 8.3858 2024-05-03 01:52:15.932559
Iter 1600, loss 8.4115 2024-05-03 01:53:31.048199
Iter 2000, loss 8.4315 2024-05-03 01:54:30.380913
Iter 2400, loss 8.4431 2024-05-03 01:55:28.193523
Iter 2800, loss 8.4572 2024-05-03 01:56:25.513457
Iter 3200, loss 8.4724 2024-05-03 01:57:23.141971
Iter 3600, loss 8.4842 2024-05-03 01:58:21.104502
Iter 4000, loss 8.4952 2024-05-03 01:59:18.962787
Iter 4400, loss 8.5036 2024-05-03 02:00:28.639238
Iter 4800, loss 8.5119 2024-05-03 02:01:46.745058
Iter 5200, loss 8.5175 2024-05-03 02:03:04.898738
Iter 5600, loss 8.5254 2024-05-03 02:04:22.195792
Iter 6000, loss 8.5344 2024-05-03 02:05:40.516137
Iter 6400, loss 8.5390 2024-05-03 02:06:58.125188
Iter 6800, loss 8.5448 2024-05-03 02:08:15.668116
Iter 7200, loss 8.5504 2024-05-03 02:09:34.064702
Iter 7600, loss 8.5574 2024-05-03 02:10:52.363671
Iter 8000, loss 8.5612 2024-05-03 02:12:09.396564
Iter 8400, loss 8.5666 2024-05-03 02:13:17.969019
Iter 8800, loss 8.5707 2024-05-03 02:14:16.121845
Iter 9200, loss 8.5740 2024-05-03 02:15:26.174101
Iter 9600, loss 8.5790 2024-05-03 02:16:43.452251
Iter 10000, loss 8.5848 2024-05-03 02:18:00.003441
Iter 10400, loss 8.5891 2024-05-03 02:19:00.338256
Iter 10800, loss 8.5920 2024-05-03 02:20:00.386810
Iter 11200, loss 8.5944 2024-05-03 02:21:18.161124
Iter 11600, loss 8.5970 2024-05-03 02:22:20.713358
Iter 12000, loss 8.5998 2024-05-03 02:23:37.424961
Iter 12400, loss 8.6014 2024-05-03 02:24:54.035767
Iter 12800, loss 8.6050 2024-05-03 02:26:10.838480
Iter 13200, loss 8.6079 2024-05-03 02:27:13.036992
Iter 13600, loss 8.6102 2024-05-03 02:28:11.243391
Iter 14000, loss 8.6117 2024-05-03 02:29:22.491035
Iter 14400, loss 8.6141 2024-05-03 02:30:40.006046
Iter 14800, loss 8.6170 2024-05-03 02:31:57.734221
Iter 15200, loss 8.6195 2024-05-03 02:33:15.631723
Iter 15600, loss 8.6206 2024-05-03 02:34:33.271176
Iter 16000, loss 8.6236 2024-05-03 02:35:50.102196
Iter 16400, loss 8.6250 2024-05-03 02:37:07.801927
Iter 16800, loss 8.6270 2024-05-03 02:38:25.135246
Iter 17200, loss 8.6288 2024-05-03 02:39:42.527475
Iter 17600, loss 8.6304 2024-05-03 02:41:00.043687
Iter 18000, loss 8.6319 2024-05-03 02:42:17.434416
Iter 18400, loss 8.6327 2024-05-03 02:43:34.873759
Iter 18800, loss 8.6342 2024-05-03 02:44:52.843561
Iter 19200, loss 8.6363 2024-05-03 02:46:09.548673
Iter 19600, loss 8.6373 2024-05-03 02:47:26.592633
Iter 20000, loss 8.6388 2024-05-03 02:48:44.335043
Iter 20400, loss 8.6401 2024-05-03 02:49:54.306142
Iter 20800, loss 8.6423 2024-05-03 02:51:11.006863
Epoch 9, loss 8.6432 =============================================
start predicting:  2024-05-03 02:53:00.058239
Iter 200, test_loss 9.0002 2024-05-03 02:54:23.916511
Iter 400, test_loss 9.0943 2024-05-03 02:54:36.093014
Iter 600, test_loss 9.0233 2024-05-03 02:54:51.314381
Iter 800, test_loss 8.9452 2024-05-03 02:55:06.264958
train_loss:8.6432	test_loss:8.9360	Recall@5:0.5325	Recall@10:0.6500	Recall@20:0.7635	NDGG@5:0.4077	NDGG10@10:0.4458	NDGG@20:0.4745	Epoch:9,9,9,9,9,9
start training:  2024-05-03 02:55:50.123262
Traceback (most recent call last):
  File "/Users/lmaciti/Desktop/tmp/Recommender System/DGRS_Research/new_main.py", line 205, in <module>
    main()
  File "/Users/lmaciti/Desktop/tmp/Recommender System/DGRS_Research/new_main.py", line 122, in main
    for user, batch_graph, label, last_item in train_data:
  File "/Users/lmaciti/Library/Python/3.9/lib/python/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
  File "/Users/lmaciti/Library/Python/3.9/lib/python/site-packages/torch/utils/data/dataloader.py", line 1329, in _next_data
    idx, data = self._get_data()
  File "/Users/lmaciti/Library/Python/3.9/lib/python/site-packages/torch/utils/data/dataloader.py", line 1295, in _get_data
    success, data = self._try_get_data()
  File "/Users/lmaciti/Library/Python/3.9/lib/python/site-packages/torch/utils/data/dataloader.py", line 1133, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/multiprocessing/queues.py", line 122, in get
    return _ForkingPickler.loads(res)
  File "/Users/lmaciti/Library/Python/3.9/lib/python/site-packages/torch/multiprocessing/reductions.py", line 514, in rebuild_storage_filename
    storage = torch.UntypedStorage._new_shared_filename_cpu(manager, handle, size)
RuntimeError: Shared memory manager connection has timed out
libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe
